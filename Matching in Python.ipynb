{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "1. **Intuition behind what we do**\n",
    "2. **Installation and technical aspects**\n",
    "3. **Matching itself**\n",
    "4. **Next steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intuition behind what we do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the few examples that we have, and it solely focuses on the procedure of matching. We expect to post other workbooks soon.  \n",
    "\n",
    "Let's refresh why you want to do matching at all.  \n",
    "\n",
    "\n",
    "Imagine that you have nonrandomized data (i.e. you didn't run a randomized control trial, a.k.a. an A/B test, to collect it; most likely, it's just a Zeta data pool). The problem here is that you can't easily compare two groups from this data to each other due to the existing effect of confounding variables. One of the tricky portions here is that these confounding variables might be in your dataset and/or they might be outside of the dataset. In the latter case, there is not much you can do (actually, you can do at least one thing that we'll cover in the next workbook). In the former case, matching can alleviate some of your pains.  \n",
    "\n",
    "If you have two groups you want to compare to each other (*one group had sessions and made purchases in the last seven days, another group had sessions and didn't make purchases in the last seven days*), you need to take users from one group and find a \"twin\" in another group. Twins are similar, and there has to be some measure of similarity. One of the most common (and intuitive) scores is a propensity score.  \n",
    "Propensity scores are calculated using linear probability, logit or probit models. Differences among these three are subtle (*a logistic regression uses a logit link function, a probit regression uses an inverse normal link function, your plain vanilla linear probability model doesn't have a link function at all*) and are not really important for this discussion. Let's just agree to use a logit approach because below we will be comparing an binary treatment.  \n",
    "The concept of the propensity score is not that hard to grasp. It is the conditional probability of being assigned to a particular treatment given a vector of observed covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "e(x_i) = Pr(z_i = 1|x_i)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "Pr(z_1,...z_n|x_1,...x_n) = \\sum_{i=1}^{n} e^{z_i} * (1-e(x_i)^{1-z_i}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "z_i = 1 \\textrm{ for treatment}\\\\\n",
    "z_i = 0 \\textrm{ for control}\\\\\n",
    "x_i \\textrm{ is the vector of observed covariates for the } i_{th} \\textrm{ subject}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it looks to you as a likelihood of a binomial distribution, you're absolutely right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you calculated the propensity score in an A/B test, comparing two groups, then the score for each participant would be 0.5. This is because in a randomized test, each observation is assigned to a group with equal probabilities.  \n",
    "So the the steps that any matching program is doing are:\n",
    "1. calculate the probabilities of being assigned to a group. Let's say, you encode users without purchases as zero in a column \"Test_Control\" and users with purchases as one. It becomes your dependent variable that you want to predict using other columns as features. Sounds like a normal ML task, right?\n",
    "2. separate this big datasets into two groups: one group was exposed to your treatment (in the example below, we're exploring whether making a saved search impacts your future purchases), another was not\n",
    "3. take a user from one group and find a user from another group that has a very similar propensity score (calculated in step 1 above). How similar? It's controlled by the threshold, and you can alter it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least: don't forget what you're trying to achieve. I think that in our domain we're usually going after a marginal contribution (or impact) of some feature on some metric (GMB or one of its proxies). Matching on its own doesn't do this; all it does is prepare your (new) dataset. It means that after matching you'll need to take some other steps. What are these steps? We cannot know in advance. Usually many practitioners calculate Average Treatment Effect (ATE) or Average Treatment Effect on the Treated (ATT). Most of the tools allow to do it immediately after matching. However, it's not what we (probably) want. That said, we can put the procedure of matching somewhere in the middle of your workflow:  \n",
    "Understanding of the problem --> Data Collection --> Reasoning about matching --> **Procedure of matching** --> Further analysis of the matched dataset.  \n",
    "Maybe we can use an anology from machine learning: when you use some distance-based algorithm, you center (sometimes it's called \"normalize\") your numerical variables around a mean of zero with standard deviation of one (z-score). Does it tell you anything about the underlying problem? No. Is it required if you want to achieve better performance? Yes.  \n",
    "That being said, this workbook merely describes only one step (from A to Z, though) and doesn't provide you a way to arrive to the final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and technical aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The truth is that R has a more developed causal inference ecosystem. They're easy to use and can do anything you want in will return results in a format that you want. However, it this tutorial we decided to use exclusively Python because it's more aligned with the company's practices and preferences of most employees. Tools in Python are either basic and not supported by their creators, or super sophisticated and complex (you really need to know what you want to achieve and why you do it in a certain way). However, we found one package that does its job well, is relatively straightforward (and you can even dig into its code if you're interested in the topic and understand what it does exactly).  \n",
    "The package is called Pymatch.  \n",
    "Usually a traditional `pip install pymatch` will do.  \n",
    "However, sometimes it won't install. Then you need another version: `pip install git+https://github.com/mc51/pymatch.git`.  \n",
    "If you're in Krylov or for some other reason don't have access to the terminal, you can potentially install directly from inside your GUI:  \n",
    "`!{sys.executable} -m pip install pymatch`  \n",
    "or  \n",
    "`!{sys.executable} -m pip install git+https://github.com/mc51/pymatch.git` respectively (Don't forget to `import sys` first).  \n",
    "\n",
    "Finally, it sometimes fails to estimate the effect of matching on categorical variables by throwing an error instead. We've found a way to correct it.  \n",
    "1. Find where your Pymatch is installed by running `pip show pymatch` (or `!{sys.executable} -m pip show pymatch`)\n",
    "2. Go there and find \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pymatch\n",
      "Version: 0.3.4.2\n",
      "Summary: Matching techniques for Observational Studies\n",
      "Home-page: https://github.com/benmiroglio/pymatch\n",
      "Author: Ben Miroglio\n",
      "Author-email: benmiroglio@gmail.com\n",
      "License: UNKNOWN\n",
      "Location: c:\\users\\mkareev\\anaconda3\\lib\\site-packages\n",
      "Requires: patsy, scipy, pandas, numpy, statsmodels, seaborn, matplotlib\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip show pymatch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
